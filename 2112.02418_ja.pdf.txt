YourTTS: 
ゼロショット多人数TTSとゼロショット音声変換をみんなで実現す
るために 

概要 

YourTTSは、多言語アプローチの力をゼロショット多言
語TTSのタスクにもたらします。本手法は、VITSモデル
をベースに、ゼロショット多言語話者および多言語学習
用にいくつかの新しい改良を加えています。その結果、
VCTKデータセットにおいて、ゼロショット多言語音声
合成でSOTA（state-of-the-
art）、ゼロショット音声変換でSOTAと同等の結果を得
ることができました。さらに、本アプローチは単一話者
のデータセットでターゲット言語において有望な結果を
達成し、低リソース言語におけるゼロショット多言語T
TSおよびゼロショット音声変換システムの可能性を開く
ものである。最後に、1分以内の音声でYourTTSモデル
を微調整し、音声の類似性と妥当な品質で最先端の結果
を達成することが可能である。これは、学習時の音声や
録音特性が大きく異なる話者に対して低合成を行うため
に重要である。 
索引用語：異言語ゼロショット多人数TTS、テキスト音
声合成、異言語ゼロショット音声変換、話者適応。 

1.  はじめに 

近年、TTS（Text-to-
Speech）システムは、深層学習のアプローチにより著し
く進歩し、音声ベースの仮想アシスタントなどのアプリ
ケーションを成功させることができるようになりました
。多くのTTSシステムは、1人の話者の音声から調整さ
れていましたが、現在、数秒間の音声を使用して、新し
い話者の音声を合成することに関心が集まっています（
学習中に見たことがない）。このアプローチは、
ゼロショット多人数TTS（ZS-TTS）と呼ばれています。 

深層学習を用いたZS-TTSは、DeepVoice 3方式を
拡張した[5]が最初に提案しました。一方、Tacotron 
[7]は、一般化エンドツーエンド損失（GE2E）を用いて
学習した話者エンコーダから抽出した外部話者埋め込み
を用いて適応し[8]、ターゲット話者と類似した音声生成
を可能にした[1]。同様に、Tacotron 2は、異なる
話者埋め込み手法を用いて、LDE埋め込みにより、
未見話者に対する音声の類似性と自然さを向上させました。
また、性別に依存したモデルを用いることで、
未視聴の話者に対する類似度が向上することを示した。
このような背景から，Attentron は，様々な参照標本
から詳細なスタイルを抽出するための注目機構を備えた
細粒度エンコーダと，粗粒度エンコーダを提案しました．
その結果，複数の参照サンプルを用いることで，未視聴
話者に対するより良い音声類似度を実現しました． 

ZSM-SS は，Wav2vec 2.0 に基づくノーマライゼー
ションアーキテクチャと外部話者エンコーダを備えた
Transformerベースのアーキテクチャである．この
アーキテクチャでは，スピーカのエンベッディング，
ピッチ，エネルギーを条件として正規化を行っている．
本論文では，Wav2vec 2.0をベースにした外部スピー
カエンコーダと正規化アーキテクチャを構成する．
SC-GlowTTS は ZS-TTSにおけるフローベースの
モデルの最初の適用例である．本論文では，
SC-GlowTTSをZS-TTSに適用することで，従来の
研究と比較して，未知の話者に対する音声類似度を
改善し，同等の品質を維持した． 

このような進歩にもかかわらず、学習時に観測される
話者と観測されない話者の間の類似性のギャップは、
まだ未解決の研究課題である。また、ZS-TTSモデルは、
学習時に相当数の話者を必要とするため、低リソース
言語において高品質なモデルを維持することが困難
である。さらに、TTSサーベイによれば、現在の
ZS-TTSモデルの品質は、特に学習時の発話特性と
異なるターゲット話者に対しては、十分に良いとは
言えないという。また、SC-GlowTTSはVCTKデータ
セットの11話者のみを用いて有望な結果を得たが、
訓練話者の数と種類を制限すると、未知の音声に
対するモデルの汎化がさらに妨げられる。 

また、ZS-TTSと並行して、多言語TTSも発展しており、
多言語のモデルを 同時に学習することを目指している。
これらのモデルのなかには、コードスイッチング、
すなわち、同じ音声を維持しながら文の一部でター
ゲット言語を変更することを可能にするものがあり、
特に興味深い。これは、ある言語から別の言語で合成
された音声を使用することを可能にするため、
ZS-TTSに有用である。 


本論文では、ゼロショット多言語音声学習と多言語
学習に焦点を当てたYourTTSを提案する。本論文では、
VCTKデータセットにおけるゼロショット多言語音声
合成の結果と、SOTAに匹敵する結果を報告する。 

私たちの新しいゼロショット多言語TTSアプローチは、
以下のような貢献をしています。 

•  英語版での最新成果。 
•  ゼロショット多言語TTSのスコープで多言語アプ
ローチを提案した最初の作品。 
•  モデル学習時にターゲット言語の1話者のみを用
いて、ターゲット言語において有望な品質と類似
性を持つゼロショット多言語TTSおよびゼロショ
ット音声変換を行うことができます。 
•  モデル学習時の声質・録音特性と大きく異なる話
者に対して、1分以内の発話でモデルの微調整を
行い、かつ良好な類似度と品質を実現する。 

各実験の音声サンプルを公開しています。 
デモサイトにて1.再現性を高めるため、ソースコードは
Coqui TTS2にて公開されています。


2.  YourTTSモデル 

YourTTSはVITSをベースにしているが、ゼロショット
多言語学習用にいくつかの新しい改良が加えられている。
まず、以前の研究とは異なり、我々のモデルでは音素の
代わりに生のテキストを入力として使用しています。
これにより、オープンソースの優れた書記素-音素変換器
がない言語でも、より現実的な結果を得ることができる。 

これまでの研究と同様、変換器ベースのテキストエン
コーダを用いる。ただし、多言語学習のために、4次元
の学習可能な言語埋め込みを各入力文字の埋め込みに
連結している。また、変換器のブロック数を10に、
隠れチャンネル数を196に増やした。デコーダは、VITS
モデルと同様に、4つのアフィン結合層[21]を積み重ね
たものを用い、各層はそれ自体が4つのWaveNet残差
ブロックを積み重ねたものとなっている。 

ボコーダとしては、HiFi-GAN バージョン1 に VITS
で導入された識別器の修正を加えたものを使用する。
さらに、効率的なエンドツーエンド学習のために、
VAE（variational autoencoder）を用いて、
TTSモデルとボコーダを接続する。このために、VITS
で提案されたPosterior Encoderを使用する。
Posterior Encoderは16個の非因果的WaveNet残差
ブロックから構成される。この潜在変数はボコーダ
およびフローベースデコーダの入力として使用される
ため、中間表現（メルスペクトログラムなど）は必要
ない。これにより、中間表現を学習することが可能と
なり、ボコーダとTTSモデルを別々に学習する2段階
アプローチシステムよりも優れた結果を得ることが
できる。さらに、入力テキストから多様なリズムの
音声を合成するために、VITSで提案された確率的
継続時間予測器を用いている。 

ここで、(+)は連結を、赤の接続はこの接続によって
勾配が伝搬されないことを、破線の接続はオプション
であることを示す。Hifi-GAN 識別器ネットワークは
簡略化のため省略した。 

このモデルにゼロショット多弁生成能力を与えるために、
フローベースデコーダ、後置エンコーダ、およびボコー
ダのすべてのアフィン結合層を外部話者埋め込みに条件
付けする。結合層の残差ブロックと後置エンコーダに
グローバルコンディショニング[22]を用いている。
また、テキストエンコーダとデコーダの出力は、それぞ
れ継続時間予測器とボコーダへ渡す前に、外部話者エン
ベッディングと合計する。要素ごとの和の前に、線形射
影層を使って次元を合わせる（図1参照）。 

また、言語間話者適用に触発され、最終損失における
Speaker Consistency Loss (SCL)を調査した。
この場合，事前に学習した話者エンコーダを用いて，
生成された音声とグランドトゥルースから話者埋め込み
を抽出し，その上でcosine類似度を最大化する。

形式的には、を話者の埋め込みを出力する関数、cos 
simを余弦類似度関数、αを最終損失におけるSCLの影響
を制御する正の実数、nをバッチサイズとすると、SCL
は次のように定義される。 
 
ここで、gとh は それぞれ、グランドトゥルースと生成
された話者音声を表す。 
VITSと同様に、z からこの潜在変数と話者埋め込みは、
波形を生成するGANベースのボコーダジェネレータの
入力として使用される。効率的なエンドツーエンドの
ボコーダ学習のために、一定長の部分列をランダムに
サンプリングする。Flow-based decoderは、潜在
変数zと話者埋め込みをPZp事前分布に関して調整する
ことを目的とする。このPZp 分布をテキストエンコーダ
の出力と整合させるために、
MAS（Monotonic Alignment Search）を使用する。
確率的継続時間予測器は、話者埋め込み、言語埋め込み、
およびMASによって得られた継続時間を入力として再認
識する。人間のような音声のリズムを生成するために、
確率的継続時間予測器の目的は、音素（ここでは擬似
音素）の継続時間の対数尤度の変分下界である。 

推論中、MASは使用されない。その代わり、PZp分布は
テキストエンコーダーによって予測され、継続時間は
確率的継続時間予測器の逆変換によってランダムノイズ
からサンプリングされ、その後、整数に変換される。
このようにして、潜在変数zp が 分布PZp からサンプ
リングされる。逆フローベース復号器は、潜在変数zp
と話者埋め込みを入力として受け、潜在変数zpを潜在
変数z に変換し、ボコーダ生成器に入力として渡す
ことで、合成波形を得ることができる。 


3.  実験風景 

3.1.  スピーカーエンコーダ 

話者エンコーダには、VoxCeleb データセットで
Prototypical Angular とSoftmax損失関数を
用いて学習した、一般に公開されているH/ASPモデル
を使用しました。このモデルは、Vox-Celeb の
テストサブセットにおいて、最先端の結果を達成する
ために選択されました。また，Multilingual 
LibriSpeech (MLS) のテストサブセットでは，
全言語を使用してモデルを評価した．このモデルは平均
EERが1.967であるのに対し、SC-GlowTTS論文で用い
られた話者エンコーダはEERが5.244であった。 

3.2.  オーディオデータセット 

我々は3つの言語を調査し、各言語につき1つのデータ
セットを使ってモデルを学習した。全てのデータセッ
トにおいて、前処理を行い、類似のラウドネスを持つ
サンプルを作成し、長い無音時間を削除した。すべて
の音声を16Khzに変換し、Webrtcvadツールキットを
用いて音声アクティビティ検出（VAD）を適用した。4を
適用し、後続の無音部分をトリミングした。さらに、
Pythonパッケージffmpeg-normalizeのRMSベースの
正規化を使用して、すべての音声を-27dBに正規化し
ました。

VCTKデータセットは、44時間の音声と109人の話者を
含み、48KHzでサンプリングされている。VCTKデータ
セットは、訓練、開発（訓練セットと同じ話者を含む）、
テストに分けられる。テストセットでは，SC-GlowTTS
の提案に従い，各アクセントから女性7名，男性4名の
計11名の話者（話者225，234，238，245，248，26
1，294，302，326，335，347）を選び，
開発及び学習セットには含まれていない話者（話者234，
238，245，261，292，326，347）をテストセットと
して選択しました．毛皮 
さらに，いくつかの実験では，モデルの学習における話
者の数を増やすために，LibriTTS  データセット の
サブセット train-clean-360 を使用しました． 

train-clean- 

100  と 

ポルトガル語。TTS-

Portugueseコーパス[35]は、ブラジル・ポルトガル
語の単一話者によるデータセットで、約10時間の音声を
48KHzでサンプリングしたものである。著者らはスタジオ
を使用していないため、このデータセットには周囲の
雑音が含まれている。我々はFullSubNetモデルを
ノイズ除去に使用し、データを16KHzに再サンプリング
した。開発には500サンプルをランダムに選択し、残りの
データセットをトレーニングに使用した。 

フランス語：LibriVoxを利用したMAILABSデータセット
のfr FRセット6.女性2人（104h）、男性3人（71h）の
音声を16KHzでサンプリングしている。 

英語における本モデルのゼロショット多言語能力を評価
するために、テスト用に確保された11人のVCTK話者を
用いる。さらに、VCTK以外の領域での性能を検証する
ために、LibriTTSデータセット[34]のサブセット
test-cleanから10話者（5F/5M）を選択しました。
ポルトガル

 
(MLS) 

LibriSpeech 

は、Multilingual 
データセットの10話者 
(5F/5M)から取得した。フランス語については、セクシ
ョン4で説明した理由により、評価用データセットを使
用しませんでした。最後に、話者適応の実験では、より
現実的な設定を模倣するために、Common Voiceデータ
セット[38]から4人の話者を使用しました。 

[33] 

3.3.  実験セットアップ 

YourTTSを使った学習実験を4回行った。 

•  実験1：VCTKデータセット（モノリンガル）を使用。 
•  実験2：VCTKとTTS-Portugueseの両データセット
（バイリンガル）を使用。 
•  実験3：VCTK、TTS-Portuguese、M-AILABS 
frenchデータセット（3ヶ国語）を使用。 
•  実験4：実験3で得られたモデルから、LibriTTSパ
ーティションtrain-clean-360の両方から1151人の
英語話者を追加して学習を継続する。 

clean-100とtrain- 

学習速度を上げるため、全ての実験において、トラ
ンスファー学習を用いた。実験1では、LJSpeech[39]で1
Mステップ学習したモデルからスタートし、VCTKデー
タセットで200Kステップ学習を継続する。ただし、提
案した変更により、重みの形状の不適合により、モデ
ルの一部の層がランダムに初期化された。実験2、3で
は、前回の実験から続けて約140kステップの学習を行
い、1言語ずつ学習する。また、各実験において、微調
整を行った。 
 
実験 3 では、SCL (Speaker Consistency Loss) 
を用いて、α 9  で  50k  ステップ学習した。
最後に、実験  4 = では、実験  3  のモデルを
Speaker  Consistency  Loss で微調整したものを
用いて学習を継続する。ZS-TTSの最新の研究ではVCTK
データセットのみを用いているが、このデータセットは
話者数が109人と少なく、録音条件のバリエーションも
少ないことに注意する必要がある。このため、VCTKのみ
で学習した場合、録音条件や音声特性が
学習時と大きく異なる新しい話者に対しては、一般に
ZS-TTSモデルはうまく汎化されない(TTSサーベイより)


3, 

モデルの学習には  NVIDIA  TESLA  V100  32GB 
64 を使用し、バッチサイズは 
である。TTSモデルの学習とボコーダHiFi-GANの識別
には、AdamW [40]を使用し、ベータ0.8と0.99、
重み減衰量 0.01、初期学習率は0.0002で、
0.999875のガンマで指数関数的に減衰する[41]。
多言語実験では、言語バランスのとれたバッチを保証する
ために、重み付きランダムサンプリング[41]を用いる。 

optimizer 

4.  結果および考察 

この論文では，[42]  と同様に，Mean  Opinion 
Score (MOS) 調査を用いて，合成音声の品質を評価する．
合成音声と元の話者の類似性を比較するために，話者
エンコーダから抽出された 2 つの音声の話者埋め込み間
の話者エンコーダコサインシ アリティ（SECS）[4]を
計算する．SECS  は  -1  から  1 の範囲で、値が
大きいほど類似性が高いことを示す[2]。本稿では、
先行研究[4]に従い、Resemblyzer[43]パッケージの
話者エンコーダを用いてSECSを計算し、先行研究との
比較を可能にした。また、[1 3 4]の研究に従い、
類似度MOS (Sim-MOS) を報告する。 

この実験では，3 つの言語を用いているが，MOS メト
リクスの計算コストが高いため，2 つの言語のみを
用いて計算した．また，[4]に従い，MOS メトリクス
の計算には2つの言語のみを使用した．また，[4]に
従い，このようなメトリクスのみを提示した． 

を、トレーニング時に未視聴の
スピーカーに適用する。 

テスト文の 

表1は、VCTKとLibriTTSのデータセットでは英語、
MLSのデータセットではポルトガル語のサブセットで、
すべての実験のMOSとSim-MOS、95%信頼区間とSECSを
示しています。 

4.1.  VCTKデータセット 

VCTKデータセットでは、実験1（モノリンガル）と実験
2＋SCL（バイリンガル）で最良の類似性結果が得られ
た。両者とも同じSECSと同じSim-
MOSを達成した．Sim-
MOSによれば、SCLの使用は改善をもたらさなかったが
、全ての実験の信頼区間が重なっており、この分析では
結論が出ない。一方、SECSでは、3実験中2実験でSCLの
使用により類似度が改善された。また、実験2について
は、両メトリクスともSCLの類似度への正の効果で一致
している。 

もう一つの注目すべき結果は、VCTKデータセット
の全ての実験において、SECSがグランドトゥルースよ
り高いことである。これは、VCTKデータセット自体の
特徴として、例えば、ほとんどの音声に大きな呼吸音が
含まれるため、説明することができます。話者エンコー
ダはこれらの特徴を扱うことができず、その結果、グラ
ンドトゥルースのSECSを低下させる可能性があります
。全体として、VCTKを用いた我々の最良の実験では、
類似性（SECSとSim-
MOS）および品質（MOS）の結果は、グランドトゥル
ースと同様であった。MOSに関する我々の結果は、VIT
Sの論文[19]によって報告されたものと一致する。しかし
、我々の修正により、このモデルは未知の話者に対して
良好な品質と類似性を維持できることが示された。最後
に、我々の最良の実験結果は、[3, 
4]と比較して、類似度と品質において優れた結果を達成
し、ゼロショット多言語TTSのためのVCTKデータセッ
トにおけるSOTAを達成した。 

4.2.  LibriTTSデータセット 

実験4では、LibriTTSの類似度が最も高くなった。この
結果は、他の実験よりも多くの話者(∼1.2k)を用いること
で、より広い範囲の音声をカバーしたためと考えられる。 
と記録条件の多様性を実現します。一方、MOS 

7
私たちは 

は、モノリンガルの場合、最良の結果を達成しました。

のテストサブセットのグランドトゥルースとして、各テ
ストスピーカーの音声をランダムに5つ選択した。SECS
とSim-
MOSのグランドトゥルースとして、話者ごとに5つの音
声をランダムに選択し、合成時に話者埋め込みの抽出に
用いた参照音声と比較したところ、SECSとSim-
MOSのグランドトゥルースとして、話者ごとに5つの音
声をランダムに選択し、合成時に話者埋め込みの抽出に
用いた参照音声と比較した。 

7 https://www.definedcrowd.com/evaluation-of-experience/ 

MOSスコアは、厳密なクラウドソーシングによって

取得されました。英語版のMOSとSim-
MOSの計算には、それぞれ276人と200人の英語ネイティ
ブの貢献者を使用した。ポルトガル語では、90人のポル
トガル語ネイティブの協力者が、両方の指標に使用され
ました。 

VCTKデータセットの第5文（speakerID 

005.txt）は、すべてのテスト話者が発話し、かつ長い文

（20ワード）であるため、評価時に話者埋め込みのため
の参照音声として使用しました。Lib-
riTTSおよびMLSポルトガル語については，十分な長さ
の参照音声を確保するため，5秒以上のものだけを考慮
して，話者ごとにランダムに1サンプル抽出しています
． 

英語でのMOS、SECS、Sim-

MOSの計算には、LibriTTSデータセットのtest-
cleanサブセットからランダムに55文を選び、20語以上の
文のみを考慮した。ポルトガル語はこの55文の翻訳を使
用した。推論の際、全ての話者をカバーし、十分な数の
文を確保するため、話者ごとに5文を合成する。すべて

 
これは主に学習用データセットの品質によるものであ
ることがわかった。実験1では、VCTKデータセットの
みを使用し、他の実験で追加したデータセットと比較
して、高い品質を実現した。 

4.3.  ポルトガル語MLSデータセット 

ポルトガル語のMLSデータセットでは、信頼区間が他
の実験と重複しているものの、実験3+SCLのMOS 
4.11±0.07が最高のMOS指標を達成しました。 
メンツ。興味深いことに、中程度の品質の単一話者デ
ータセットでポル 
トガル語を学習したモデルは、ゼロショット多人数話
者合成で は良好な品質に達することができます。 
の論文。実験3はSim-
MOSによると最良の実験である（3.19±0.10）が、信頼
区間を考慮すると他の実験と重複している。このデー
タセットでは、Sim-MOS 
とSECSは一致しない。SECSの指標に基づくと、実験4
+SCLでより高い類似度を持つモデルが得られた。これ
は、LibriTTSのデータセットが多様であることに起因す
ると考えられる。また、このデータセットはオーディ
オブックで構成されているため、MLSデータセットと
録音特性や韻律が似ている傾向がある。SECSとSim-
MOSのこの差は、Sim-
MOSの信頼区間によって説明できると考えている。最後
に、このデータセットで達成されたSim-
MOSは、我々のモデルが1人の男性話者のみを用いて訓
練されたことを考慮すると、関連性がある。 

 
の品質が若干低下するようである。これは、SCL 
を使用することで、モデルが基準オーディオに存在する
録音特性を生成するように学習し、より多くの歪みやノ
イズを生成するためであると考えられる。ただし 

ポルトガル語 

男女別のメトリクスを分析すると、男性話者と女性

話者のみを考慮した実験4のMOSは、それぞれ 
4.14±0.11と3.79±0.12である。また、男性話者と女性話
者のSim-
MOSは、それぞれ3.29±0.14と2.84±0.12である。 
0.14.したがって、我々のモデルのポルトガル語における
性能は 
は性別に影響される。これは、我々のモデルがポルトガ
ル語の女性話者で訓練されていなかったために起こった
ことだと考えています。それにもかかわらず、我々のモ
デルはポルトガル語の女性の音声を生成することができ
ました。アッテントロンモデルでは、Sim-
Simを達成しました。 
約100人の話者と英語学習を行った結果、MOSは3.30±0.06
となった。信頼度インター 
また、ターゲット言語が男性1名の場合でも、Sim-
MOSを達成することができました。したがって、我々の
アプローチは、低リソース言語におけるゼロショット多
言語TTSモデル開発のためのソリューションになり得る
と考えている。 

フランス語も含めると（つまり実験3）、ポルトガル

語の品質と類似度（SECSによる）の両方が向上したよ
うに見える。これは、M-
AILABSのフランス語データセットがポルトガル語コー
パスよりも高品質であること、また、言語ごとにバッチ
をバランスさせることにより、モデル学習時にバッチの
中の低品質音声が減少するためと考えられます。また、
TTS-
Portugueseは単一話者のデータセットであり、実験2で言
語ごとにバッチをバランスさせると、バッチの半分が男
性1人のみで構成されるため、類似度の増加が説明でき
る。フランス語が追加された場合、ポルトガル語話者の
音声で構成されるバッチは3分の1になります。 

4.4.  スピーカーの整合性喪失 

話者整合性損失（SCL）を用いることで、SECSで測定
した類似度が改善された。一方、Sim-MOSでは、実験
間の信頼区間は、SCLが類似性を向上させたと断言する
ことはできない。しかし、SECSは訓練時に見られなかっ
た特性を記録することで、汎化することができると考え
ている。例えば、実験1では、Lib-riTTSデータセット
の録音特性を学習で見ていないモデルが、このデータ
セットに対するテストでは、SECSとSim-MOSの両方の
メトリクスがSCLのおかげで類似度の向上を示しました。
一方、SCLを用いると、生成される音声


 
5.  ゼロショット音声変換 

SC-GlowTTS[4]モデルと同様に、エンコーダには話者の
身元に関する情報を与えないので、エンコーダが予測する
分散は、強制的に話者非依存になる。そこで、YourTTS
では、モデルの後置エンコーダ、デコーダ、HiFi-GAN
ジェネレータを用いて音声変換を行うことができる。
また、YourTTSに外部の話者埋め込みを条件とすること
で、ゼロショット音声変換の設定において、未視聴話者の
音声を模倣することが可能となりました。 また、[44]
では、AutoVC[45]とNoiseVC[44]のMOSとSim-MOS
を、VCTKの10話者について、学習中に見かけなかった
モデルで報告されています。この結果を比較するために，
VCTKのテストサブセットから8話者（4M/4F）を選択した．
また，[44]では10人の話者を用いているが，男女比の
関係から8人のみとした． 

Sim-MOS 

は

、女性、男女混合の話者間の伝達を個別に比較しました
。この分析では、各話者について、3秒以上のサンプル
だけを考慮し、ランダムに参照サンプルを選択し、他の
各話者の音声で転送を生成しました。また、英語話者と
ポルトガル語話者の間の音声の伝達を分析した。MOS 
と 4 章で述べたように計算する。ただし、英語と
ポルトガル語（pt-en、en-pt）間の音声送受信を行う
場合の Sim-MOS の計算では、参照サンプルが一方の
言語であり、他方の言語で送受信を行うため、両言語の
評価者（英語とポルトガル語でそれぞれ 58 名、40 名）
を使用した。 表2は、これらの実験におけるMOSと
Sim-MOSを示したものです。ゼロショット音声変換のサンプ
ルは、デモページにあります。8. 

5.1.  言語内結果 

さらに、ポルトガル語に対するモデルの汎化性を分析し、
モデルが1人の話者のみで学習された言語において我々の
モデルが達成した結果を検証するために、MLSポルトガル
語データセットのテストサブセットから8人の話者
（4M/4F）を使用しました。したがって、どちらの言語
でも、学習で使用されなかった話者を使用しています。
より深い分析のために、[45]に従って、男性ただし、
高品質なリファレンスサンプルを用いたテストでは、その
ようなことはありません。 を使用することで、高品質な
音声を生成することができます。 

英語話者から他の英語話者へのゼロショット音声変換
（en-en）において、我々のモデルはMOSが 4.20±0.05、
Sim-MOSは4.07±0.06となった。での比較のために 

のMOSとSim-MOSの結果を報告した[44]。 
は、AutoVC [45]とNoiseVC 
[44]モデルである。学習時に見かけなかった10人のVCTK
話者に対して、AutoVCモデルは以下を達成した。 

MOSは3.54 ±1.089となり、Sim-MOSは1.91±1.34と
なりました。一方、NoiseVCモデルは、MOSが3.38
±1.35、Sim-MOSが3.05±1.25となりました。
したがって、本モデルはゼロショット音声変換において、
SOTAと同等の結果を得ることができた 
をVCTKデータセットで学習させた。このモデルはより
多くのデータと話者を用いて学習させたが、セクション
4におけるVCTKデータセットの類似度の結果は、VCTK
データセットのみを用いて学習させたモデル（実験1）
が、本セクションで検討したモデル（実験4）よりも優
れた類似度を示していることを示唆している。したがっ
て、YourTTSは、VCTKデータセットのみを用いて学習
・評価した場合、ゼロショット音声変換において、非常
に近い結果、あるいは、優れた結果を得ることができる
と考えている。 

ポルトガル語話者から別のポルトガル語話者へのゼ
ロショット音声変換において、我々のモデルはMOS 3.64 
± 0.09、Sim-MOS 3.43 ± 0.09を達成した。また 
音声転送において、我々のモデルの性能が著しく低いこ
と 
女性話者間の類似度 
は、男性話者間の移動度 
と比較して高い。これは、ポルトガル語には女性話者が
少ないためと考えられる。 
を学習させた。また、このモデルでは、ポルトガル語の
女性の声を見たことがなくても、ポルトガル語の女性の
声を近似的に再現することができる。 

5.2.  クロスリンガル結果 

どうやら、英語話者とポルトガル語話者の間の転送は、
ポルトガル語話者間の転送と同じようにうまくいくよう
です。しかし、ポルトガル語話者から英語話者への転送
（pt-
en）では、MOSスコアの品質が低下しています。これは
、特に、ポルトガル語話者から英語話者への音声変換の
品質が低いことに起因しています。一般に、上述したよ
うに、モデルの学習において女性話者が不足しているた
め、女性話者への転送は悪い結果をもたらす。この場合
、ポルトガル語の男性話者の音声を英語の女性話者の音
声に変換する必要があるため、課題はさらに大きくなり
ます。 

英語では、変換の際、話者の性別はモデルの性能に
大きな影響を与えなかった。しかし、ポルトガル語を含
む変換では、モデルの学習に女性の声がないため、汎化
には支障があった。 

6.  スピーカーの適合性 

このような録音条件の違いは、ゼロショット多人数音声
合成の課題である。また、学習時の音声と大きく異なる
音声を持つ話者も課題となる[13]。しかし、新しい話者
や録音条件への適応の可能性を示すために、我々は20秒
から61秒の音声サンプルを選択した。 

9 

なお、著者らは結果を実際の図 ではなくグラフで示した
ため

を、Com-mon 
Voice 
[38]データセットのポルトガル語話者2名と英語話者2名
（1M/1F）に対して実施した。この4人の話者を用いて
、実験4のチェックポイントに対して、話者整合性損失
を用いて、各話者個別に微調整を行う。 

微調整の間、多言語合成が損なわれないように、実
4 

験 
で使用したすべてのデータセットを使用した。ただし
、適応された話者からのサンプルがバッチの4分の1に
なるように、重み付きランダムサンプリング[41]を使用
する。この方法で1500ステップの学習を行う。評価に
は、セクション4で説明したのと同じアプローチを用い
る。 

表3は、各話者の性別、総時間（秒）、学習時に使
用したサンプル数、および、グランドトゥルース（GT
）、ゼロショット多人数TTSモード（ZS）、話者サン
プルによる微調整（FT）のSECS、MOS、Sim-
MOSの指標を示したものである。 

一般に、学習時に見られなかった録音特性を持つ話
者の1分未満の音声を用いたモデルの微調整は、すべて
の実験で類似度を有意に改善し、非常に有望な結果を
得た。 

英語では、ゼロショット多人数TTSモードでの本モ
デルの結果は既に良好で、微調整後は男性話者、女性
話者ともにグランドトゥルースに匹敵するSim-MOSを
達成しました。また、微調整後のモデルは、グランド
トゥルースよりも大きなSECSを達成しており、これは
既に過去の実験でも確認されています。この現象は、
モデルが録音特性や参照サンプルの歪みをコピーする
ように学習し、他の実スピーカーサンプルに対して優位
に立つことで説明できると考えています。 

ポルトガル語では、ゼロショットと比較すると、微調整
は自然さを少し犠牲にすることで、より良い類似性を
得ることができるようです。については 男性スピーカー
では、Sim-MOSが3.35±0.12から その話者については、
わずか31秒の発話で微調整を行った結果、4.19±0.07と
なった。女性話者の場合、類似度の向上は さらに、
"ent "については、ゼロショット時の2.77±0.15から、
わずか20秒の発話で4.43±0.06に向上させることができ
ました。 

しかし、表3は、使用する音声の量と音声の自然さ
（MOS）の間に直接的な関係があることを示している
ようです。話者の音声を約1分間使用した場合、我々の
モデルは話者の音声特性をコピーすることができ、ゼ
ロショットモードと比較して自然度を高めることも可
能です。一方、44秒以下の音声を使用すると、ゼロシ
ョットやグランドトゥルースモデルと比較して、生成
される音声の品質/自然さが低下する。したがって、我
々のモデルはわずか20秒の発話で話者の発話特性をコ
ピーする良好な結果を示していますが、より高い品質
を可能にするためには45秒以上の発話がより適切であ
ると言えます。最後に、モデルを微調整すると、主に
学習で使用する話者の少ないポルトガル語やフランス
語で、音声変換が大幅に改善されることにも気づきま
した。 

表3：話者適応実験のSECS、MOS、Sim-MOSと95%信頼区間。 

de 

and 

Council 

Superior 

Pessoal 
- 
N´vel 
Brasil）のファイナンスコード001、およびCNPq（Nationa
l 
Scientific 
of 
Technological 
Development）のグラント304266/2020-
5の一部によって資金提供された。さらに、本研究の一部
は、人工知能エクセレンスセンター（CEIA）より資金提
供を受けています。10文部省高等教育局（SESU/MEC）お
よびサイバーラボグループの助成によるプロジェクトを
通じて行われました。11.また、産業レベルのMOSテスト
を可能にしたDefined.aiに感謝したい。12のおかげで、産
業レベルのMOSテストが簡単に利用できるようになりま
した。最後に、Coqui TTSレポ-

ジのすべての寄稿者に感謝します。 

7.  結論、限界、今後の課題 

本研究では、VCTKデータセットにおいて、ゼロショッ
ト多言語TTSとゼロショット音声合成でSOTAを達成し
たYourTTSを発表した。さらに、単一話者のデータセッ
トのみを用いて、我々のモデルがターゲット言語におい
て有望な結果を得ることができることを示す。さらに、
学習時の音声と録音条件が大きく異なる話者に対して、
1分以内の発話で新しい音声に適応できることを示す。 
しかし、我々のモデルにはいくつかの限界がある。
すべての言語のTTS実験において、我々のモデルは確率
的持続時間予測器において不安定であり、一部の話者と

文において、不自然な持続時間を生成している。また、
特にポルトガル語では、いくつかの単語で誤った発音が
発生することがあります。35, 46, 19]とは異なり、
我々は音写を使用していないため、この
ような問題が発生しやすくなっています。ポルトガル語
の音声変換では，女性の音声を学習していないため，話
者の性別がモデルの性能に大きく影響します．話者適応
では、20秒間の発話で話者の発話特性をコピーすること
に成功したが、45秒以上の発話があれば、より高品質に
変換できる。 

今後は、YourTTSモデルの継続時間予測機能の改善
や、より多くの言語での学習を行う予定である。また、
低リソース環境における自動音声認識モデルの学習にお
けるデータ補強への応用も検討する予定です。 
